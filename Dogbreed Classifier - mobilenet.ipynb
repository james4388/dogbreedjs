{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import mobilenet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "from classes import CLASSES, LABELS_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224, 224)\n",
    "base_model = mobilenet.MobileNet(include_top=False, input_shape=(*image_size, 3), weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorganize_data(label_file='./dataset/labels.csv',\n",
    "                    base_dir='./dataset/train/',\n",
    "                    train_dir=None,\n",
    "                    validation_dir=None, validation_split=0.1, ext='.jpg'):\n",
    "    # Read label file to get list of file name and label\n",
    "    data_by_class = {}\n",
    "    with open(label_file, 'r') as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            filename, label = line.split(',')\n",
    "            filename = filename.strip()\n",
    "            label = label.strip()\n",
    "            if label not in data_by_class:\n",
    "                data_by_class[label] = []\n",
    "            data_by_class[label].append(filename)\n",
    "    # Create dirs\n",
    "    validation_split = 0.1\n",
    "    train_dir = train_dir or os.path.join(base_dir, 'train')\n",
    "    validation_dir = validation_dir or os.path.join(base_dir, 'validation')\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    # Moving everything into its folder\n",
    "    for label, files in data_by_class.items():\n",
    "        label_dir_train = os.path.join(train_dir, label)\n",
    "        os.mkdir(label_dir_train)\n",
    "        label_dir_val = os.path.join(validation_dir, label)\n",
    "        os.mkdir(label_dir_val)\n",
    "\n",
    "        val_index = len(files) * validation_split\n",
    "        for i, filename in enumerate(files):\n",
    "            if ext:\n",
    "                filename += ext\n",
    "            old_path = os.path.join(base_dir, filename)\n",
    "            if os.path.isfile(old_path):\n",
    "                if (i + 1) < val_index:\n",
    "                    os.rename(old_path, os.path.join(label_dir_val, filename))\n",
    "                else:\n",
    "                    os.rename(old_path, os.path.join(label_dir_train, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze bottom layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "def get_top_model(base_model):\n",
    "    top_input = Input(shape=base_model.output_shape[1:])\n",
    "    x = Dense(1024, activation=\"relu\", name='dense1024')(top_input)\n",
    "    x = Dropout(0.5, name='drop05')(x)\n",
    "    x = Dense(512, activation=\"relu\", name='dense512')(x)\n",
    "    x = Dropout(0.2, name='drop02')(x)\n",
    "    output = Dense(len(CLASSES), activation=\"softmax\", name='final')(x)\n",
    "    model = Model(input=top_input, output=output)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer='adam',\n",
    "        metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def get_full_model(base_model, top_model):\n",
    "    full_output = top_model(base_model.output)\n",
    "    full_model = Model(input=base_model.input, output=full_output)\n",
    "    full_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=SGD(lr=5e-5, momentum=0.9),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return full_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, path):\n",
    "    img = load_img(path, target_size=(224, 224))\n",
    "    img_arr = img_to_array(img)\n",
    "    inp = preprocess_input(img_arr)\n",
    "    inp = np.expand_dims(inp, axis=0)\n",
    "    preds = model.predict(inp)\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9357 images belonging to 122 classes.\n",
      "Found 1015 images belonging to 122 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen =  ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './dataset/images/train/', \n",
    "    target_size=image_size,\n",
    "    batch_size=25,\n",
    "    class_mode='categorical', shuffle=False)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    './dataset/images/validation//', \n",
    "    target_size=image_size,\n",
    "    batch_size=25,\n",
    "    class_mode='categorical', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = base_model.predict_generator(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('bottleneck_features.h5', 'w')\n",
    "hf.create_dataset('bottleneck_features_train', data=bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_val = base_model.predict_generator(val_generator)\n",
    "hf.create_dataset('bottleneck_features_val', data=bottleneck_features_val)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('bottleneck_features.h5', 'r')\n",
    "bottleneck_features_train = hf.get('bottleneck_features_train').value\n",
    "bottleneck_features_val = hf.get('bottleneck_features_val').value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train == bottleneck_features_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.array(train_generator.classes)\n",
    "Y_train = np.zeros((len(train_generator.classes), len(train_generator.class_indices)))\n",
    "Y_train[np.arange(len(train_generator.classes)), indices] = 1\n",
    "indices = np.array(val_generator.classes)\n",
    "Y_val = np.zeros((len(val_generator.classes), len(train_generator.class_indices)))\n",
    "Y_val[np.arange(len(val_generator.classes)), indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhutrinh/dogbreeed/env/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"fi...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "top_model = get_top_model(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "9357/9357 [==============================] - 3s 298us/step - loss: 3.1524 - acc: 0.2468\n",
      "Epoch 2/40\n",
      "9357/9357 [==============================] - 2s 243us/step - loss: 1.5867 - acc: 0.5279\n",
      "Epoch 3/40\n",
      "9357/9357 [==============================] - 2s 241us/step - loss: 1.3118 - acc: 0.6057\n",
      "Epoch 4/40\n",
      "9357/9357 [==============================] - 2s 260us/step - loss: 1.1315 - acc: 0.6475\n",
      "Epoch 5/40\n",
      "9357/9357 [==============================] - 2s 242us/step - loss: 1.0197 - acc: 0.6821\n",
      "Epoch 6/40\n",
      "9357/9357 [==============================] - 2s 247us/step - loss: 0.9292 - acc: 0.7054\n",
      "Epoch 7/40\n",
      "9357/9357 [==============================] - 3s 274us/step - loss: 0.8422 - acc: 0.7344\n",
      "Epoch 8/40\n",
      "9357/9357 [==============================] - 3s 275us/step - loss: 0.7721 - acc: 0.7547\n",
      "Epoch 9/40\n",
      "9357/9357 [==============================] - 3s 268us/step - loss: 0.7237 - acc: 0.7646\n",
      "Epoch 10/40\n",
      "9357/9357 [==============================] - 3s 269us/step - loss: 0.6797 - acc: 0.7781\n",
      "Epoch 11/40\n",
      "9357/9357 [==============================] - 3s 276us/step - loss: 0.6614 - acc: 0.7860\n",
      "Epoch 12/40\n",
      "9357/9357 [==============================] - 3s 276us/step - loss: 0.5909 - acc: 0.8040\n",
      "Epoch 13/40\n",
      "9357/9357 [==============================] - 3s 277us/step - loss: 0.5460 - acc: 0.8192\n",
      "Epoch 14/40\n",
      "9357/9357 [==============================] - 3s 279us/step - loss: 0.5183 - acc: 0.8241\n",
      "Epoch 15/40\n",
      "9357/9357 [==============================] - 3s 286us/step - loss: 0.4993 - acc: 0.8315\n",
      "Epoch 16/40\n",
      "9357/9357 [==============================] - 3s 283us/step - loss: 0.5031 - acc: 0.8316\n",
      "Epoch 17/40\n",
      "9357/9357 [==============================] - 3s 284us/step - loss: 0.4918 - acc: 0.8354\n",
      "Epoch 18/40\n",
      "9357/9357 [==============================] - 3s 317us/step - loss: 0.4840 - acc: 0.8379\n",
      "Epoch 19/40\n",
      "9357/9357 [==============================] - 3s 311us/step - loss: 0.4369 - acc: 0.8529\n",
      "Epoch 20/40\n",
      "9357/9357 [==============================] - 3s 307us/step - loss: 0.4468 - acc: 0.8504\n",
      "Epoch 21/40\n",
      "9357/9357 [==============================] - 3s 297us/step - loss: 0.4213 - acc: 0.8606\n",
      "Epoch 22/40\n",
      "9357/9357 [==============================] - 3s 291us/step - loss: 0.3897 - acc: 0.8705\n",
      "Epoch 23/40\n",
      "9357/9357 [==============================] - 3s 290us/step - loss: 0.3701 - acc: 0.8765\n",
      "Epoch 24/40\n",
      "9357/9357 [==============================] - 3s 293us/step - loss: 0.3926 - acc: 0.8684\n",
      "Epoch 25/40\n",
      "9357/9357 [==============================] - 3s 299us/step - loss: 0.3731 - acc: 0.8751\n",
      "Epoch 26/40\n",
      "9357/9357 [==============================] - 3s 297us/step - loss: 0.3671 - acc: 0.8766\n",
      "Epoch 27/40\n",
      "9357/9357 [==============================] - 3s 297us/step - loss: 0.3836 - acc: 0.8718\n",
      "Epoch 28/40\n",
      "9357/9357 [==============================] - 3s 296us/step - loss: 0.3579 - acc: 0.8807\n",
      "Epoch 29/40\n",
      "9357/9357 [==============================] - 3s 324us/step - loss: 0.3230 - acc: 0.8893\n",
      "Epoch 30/40\n",
      "9357/9357 [==============================] - 3s 311us/step - loss: 0.3073 - acc: 0.8964\n",
      "Epoch 31/40\n",
      "9357/9357 [==============================] - 3s 302us/step - loss: 0.3170 - acc: 0.8920\n",
      "Epoch 32/40\n",
      "9357/9357 [==============================] - 3s 300us/step - loss: 0.3377 - acc: 0.8905\n",
      "Epoch 33/40\n",
      "9357/9357 [==============================] - 3s 303us/step - loss: 0.3359 - acc: 0.8921\n",
      "Epoch 34/40\n",
      "9357/9357 [==============================] - 3s 311us/step - loss: 0.2832 - acc: 0.9110\n",
      "Epoch 35/40\n",
      "9357/9357 [==============================] - 3s 317us/step - loss: 0.3301 - acc: 0.8958\n",
      "Epoch 36/40\n",
      "9357/9357 [==============================] - 3s 326us/step - loss: 0.3090 - acc: 0.9031\n",
      "Epoch 37/40\n",
      "9357/9357 [==============================] - 3s 314us/step - loss: 0.3103 - acc: 0.9011\n",
      "Epoch 38/40\n",
      "9357/9357 [==============================] - 3s 306us/step - loss: 0.2988 - acc: 0.9040\n",
      "Epoch 39/40\n",
      "9357/9357 [==============================] - 3s 304us/step - loss: 0.2895 - acc: 0.9069\n",
      "Epoch 40/40\n",
      "9357/9357 [==============================] - 3s 333us/step - loss: 0.3246 - acc: 0.8945\n"
     ]
    }
   ],
   "source": [
    "history = top_model.fit(bottleneck_features_train, Y_train, batch_size=50, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015/1015 [==============================] - 0s 225us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1110828039094145, 0.7349753695168518]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_model.evaluate(bottleneck_features_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save_weights('top-mblnet.w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhutrinh/dogbreeed/env/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"mo...)`\n"
     ]
    }
   ],
   "source": [
    "final_model = get_full_model(base_model, top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_by_index = {v:k for k,v in train_generator.class_indices.items()}\n",
    "CLASSES = [label_by_index[i] for i in label_by_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save('dogbreed.h5')\n",
    "# top_model = load_model('./dogbreed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.fit_generator(generator=train_generator, epochs=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs\n",
    "tfjs.converters.save_keras_model(final_model, './js_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "with CustomObjectScope({'relu6': mobilenet.relu6,'DepthwiseConv2D': mobilenet.DepthwiseConv2D}):\n",
    "    model = load_model('dogbreed-mobilenet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(model, path):\n",
    "    p = predict(model, path)\n",
    "    top_indices = p.argsort()[-5:][::-1]\n",
    "    result = [(CLASSES[i], p[i],) for i in top_indices]\n",
    "    result.sort(key=lambda x: x[1], reverse=True)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('malamute', 0.7079626),\n",
       " ('eskimo_dog', 0.12673402),\n",
       " ('samoyed', 0.08253971),\n",
       " ('siberian_husky', 0.07271839),\n",
       " ('collie', 0.007111568)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_label(model, './cuteness2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to unfreeze layer before save to js otherwise not work\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('test.wh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('test.wh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Layer.add_weight of <keras.engine.training.Model object at 0x123949390>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import CustomObjectScope\n",
    "import tensorflowjs as tfjs\n",
    "with CustomObjectScope({'relu6': mobilenet.relu6,'DepthwiseConv2D': mobilenet.DepthwiseConv2D}):\n",
    "    tfjs.converters.save_keras_model(model, './js_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K\n",
    "import tensorflow as tf\n",
    "sess = K.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soft-coated_wheaten_terrier',\n",
       " 'old_english_sheepdog',\n",
       " 'otterhound',\n",
       " 'komondor',\n",
       " 'irish_wolfhound']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[CLASSES[i] for i in np.argsort(predict(model, './cuteness1.jpg'))[::-1][:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'affenpinscher': 0,\n",
       " 'afghan_hound': 1,\n",
       " 'african_hunting_dog': 2,\n",
       " 'airedale': 3,\n",
       " 'american_staffordshire_terrier': 4,\n",
       " 'appenzeller': 5,\n",
       " 'australian_terrier': 6,\n",
       " 'basenji': 7,\n",
       " 'basset': 8,\n",
       " 'beagle': 9,\n",
       " 'bedlington_terrier': 10,\n",
       " 'bernese_mountain_dog': 11,\n",
       " 'black-and-tan_coonhound': 12,\n",
       " 'blenheim_spaniel': 13,\n",
       " 'bloodhound': 14,\n",
       " 'bluetick': 15,\n",
       " 'border_collie': 16,\n",
       " 'border_terrier': 17,\n",
       " 'borzoi': 18,\n",
       " 'boston_bull': 19,\n",
       " 'bouvier_des_flandres': 20,\n",
       " 'boxer': 21,\n",
       " 'brabancon_griffon': 22,\n",
       " 'briard': 23,\n",
       " 'brittany_spaniel': 24,\n",
       " 'bull_mastiff': 25,\n",
       " 'cairn': 26,\n",
       " 'cardigan': 27,\n",
       " 'cat': 28,\n",
       " 'chesapeake_bay_retriever': 29,\n",
       " 'chihuahua': 30,\n",
       " 'chow': 31,\n",
       " 'clumber': 32,\n",
       " 'cocker_spaniel': 33,\n",
       " 'collie': 34,\n",
       " 'curly-coated_retriever': 35,\n",
       " 'dandie_dinmont': 36,\n",
       " 'dhole': 37,\n",
       " 'dingo': 38,\n",
       " 'doberman': 39,\n",
       " 'english_foxhound': 40,\n",
       " 'english_setter': 41,\n",
       " 'english_springer': 42,\n",
       " 'entlebucher': 43,\n",
       " 'eskimo_dog': 44,\n",
       " 'flat-coated_retriever': 45,\n",
       " 'french_bulldog': 46,\n",
       " 'german_shepherd': 47,\n",
       " 'german_short-haired_pointer': 48,\n",
       " 'giant_schnauzer': 49,\n",
       " 'golden_retriever': 50,\n",
       " 'gordon_setter': 51,\n",
       " 'great_dane': 52,\n",
       " 'great_pyrenees': 53,\n",
       " 'greater_swiss_mountain_dog': 54,\n",
       " 'groenendael': 55,\n",
       " 'ibizan_hound': 56,\n",
       " 'irish_setter': 57,\n",
       " 'irish_terrier': 58,\n",
       " 'irish_water_spaniel': 59,\n",
       " 'irish_wolfhound': 60,\n",
       " 'italian_greyhound': 61,\n",
       " 'japanese_spaniel': 62,\n",
       " 'keeshond': 63,\n",
       " 'kelpie': 64,\n",
       " 'kerry_blue_terrier': 65,\n",
       " 'komondor': 66,\n",
       " 'kuvasz': 67,\n",
       " 'labrador_retriever': 68,\n",
       " 'lakeland_terrier': 69,\n",
       " 'leonberg': 70,\n",
       " 'lhasa': 71,\n",
       " 'malamute': 72,\n",
       " 'malinois': 73,\n",
       " 'maltese_dog': 74,\n",
       " 'mexican_hairless': 75,\n",
       " 'miniature_pinscher': 76,\n",
       " 'miniature_poodle': 77,\n",
       " 'miniature_schnauzer': 78,\n",
       " 'newfoundland': 79,\n",
       " 'no_dog': 80,\n",
       " 'norfolk_terrier': 81,\n",
       " 'norwegian_elkhound': 82,\n",
       " 'norwich_terrier': 83,\n",
       " 'old_english_sheepdog': 84,\n",
       " 'otterhound': 85,\n",
       " 'papillon': 86,\n",
       " 'pekinese': 87,\n",
       " 'pembroke': 88,\n",
       " 'pomeranian': 89,\n",
       " 'pug': 90,\n",
       " 'redbone': 91,\n",
       " 'rhodesian_ridgeback': 92,\n",
       " 'rottweiler': 93,\n",
       " 'saint_bernard': 94,\n",
       " 'saluki': 95,\n",
       " 'samoyed': 96,\n",
       " 'schipperke': 97,\n",
       " 'scotch_terrier': 98,\n",
       " 'scottish_deerhound': 99,\n",
       " 'sealyham_terrier': 100,\n",
       " 'shetland_sheepdog': 101,\n",
       " 'shih-tzu': 102,\n",
       " 'siberian_husky': 103,\n",
       " 'silky_terrier': 104,\n",
       " 'soft-coated_wheaten_terrier': 105,\n",
       " 'staffordshire_bullterrier': 106,\n",
       " 'standard_poodle': 107,\n",
       " 'standard_schnauzer': 108,\n",
       " 'sussex_spaniel': 109,\n",
       " 'tibetan_mastiff': 110,\n",
       " 'tibetan_terrier': 111,\n",
       " 'toy_poodle': 112,\n",
       " 'toy_terrier': 113,\n",
       " 'vizsla': 114,\n",
       " 'walker_hound': 115,\n",
       " 'weimaraner': 116,\n",
       " 'welsh_springer_spaniel': 117,\n",
       " 'west_highland_white_terrier': 118,\n",
       " 'whippet': 119,\n",
       " 'wire-haired_fox_terrier': 120,\n",
       " 'yorkshire_terrier': 121}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABELS_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
